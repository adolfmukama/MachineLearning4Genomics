{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3dbb75b0",
      "metadata": {
        "id": "3dbb75b0"
      },
      "outputs": [],
      "source": [
        "#loading libraries for scraping twitter data\n",
        "import pandas as pd\n",
        "# import snscrape.modules.twitter as sntwitter\n",
        "import itertools\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5a5ff135",
      "metadata": {
        "id": "5a5ff135"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('tweets.csv',index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "561ca788",
      "metadata": {},
      "outputs": [],
      "source": [
        "#reset author to a column\n",
        "df = df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0ebbd0fd",
      "metadata": {
        "id": "0ebbd0fd",
        "outputId": "37ed183b-cb7c-4d49-c1fc-72726532e0a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>country</th>\n",
              "      <th>date_time</th>\n",
              "      <th>id</th>\n",
              "      <th>language</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>number_of_likes</th>\n",
              "      <th>number_of_shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>katyperry</td>\n",
              "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12/01/2017 19:52</td>\n",
              "      <td>8.196330e+17</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7900</td>\n",
              "      <td>3472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>katyperry</td>\n",
              "      <td>@barackobama Thank you for your incredible gra...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11/01/2017 08:38</td>\n",
              "      <td>8.191010e+17</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3689</td>\n",
              "      <td>1380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>katyperry</td>\n",
              "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11/01/2017 02:52</td>\n",
              "      <td>8.190140e+17</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10341</td>\n",
              "      <td>2387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>katyperry</td>\n",
              "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11/01/2017 02:44</td>\n",
              "      <td>8.190120e+17</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10774</td>\n",
              "      <td>2458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>katyperry</td>\n",
              "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10/01/2017 05:22</td>\n",
              "      <td>8.186890e+17</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17620</td>\n",
              "      <td>4655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index     author                                            content  \\\n",
              "0      0  katyperry  Is history repeating itself...?#DONTNORMALIZEH...   \n",
              "1      1  katyperry  @barackobama Thank you for your incredible gra...   \n",
              "2      2  katyperry                Life goals. https://t.co/XIn1qKMKQl   \n",
              "3      3  katyperry            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
              "4      4  katyperry  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
              "\n",
              "  country         date_time            id language  latitude  longitude  \\\n",
              "0     NaN  12/01/2017 19:52  8.196330e+17       en       NaN        NaN   \n",
              "1     NaN  11/01/2017 08:38  8.191010e+17       en       NaN        NaN   \n",
              "2     NaN  11/01/2017 02:52  8.190140e+17       en       NaN        NaN   \n",
              "3     NaN  11/01/2017 02:44  8.190120e+17       en       NaN        NaN   \n",
              "4     NaN  10/01/2017 05:22  8.186890e+17       en       NaN        NaN   \n",
              "\n",
              "   number_of_likes  number_of_shares  \n",
              "0             7900              3472  \n",
              "1             3689              1380  \n",
              "2            10341              2387  \n",
              "3            10774              2458  \n",
              "4            17620              4655  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "369e64ca",
      "metadata": {
        "id": "369e64ca",
        "outputId": "e48d3d54-d2b3-4753-9050-a6593daa5fc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(52542, 11)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "81e56572",
      "metadata": {
        "id": "81e56572",
        "outputId": "48ce27f4-0a7f-4b52-dfe9-8b88fd98999a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>country</th>\n",
              "      <th>date_time</th>\n",
              "      <th>id</th>\n",
              "      <th>language</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>number_of_likes</th>\n",
              "      <th>number_of_shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52537</th>\n",
              "      <td>52537</td>\n",
              "      <td>ddlovato</td>\n",
              "      <td>Life couldn't be better right now. üòä</td>\n",
              "      <td>NaN</td>\n",
              "      <td>06/01/2015 23:10</td>\n",
              "      <td>5.526030e+17</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>32799</td>\n",
              "      <td>23796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52538</th>\n",
              "      <td>52538</td>\n",
              "      <td>ddlovato</td>\n",
              "      <td>First Monday back in action. I'd say 21.6 mile...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>06/01/2015 02:17</td>\n",
              "      <td>5.522880e+17</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21709</td>\n",
              "      <td>12511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52539</th>\n",
              "      <td>52539</td>\n",
              "      <td>ddlovato</td>\n",
              "      <td>Crime shows, buddy, snuggles = the perfect Sun...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>05/01/2015 03:42</td>\n",
              "      <td>5.519470e+17</td>\n",
              "      <td>en</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25269</td>\n",
              "      <td>15583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52540</th>\n",
              "      <td>52540</td>\n",
              "      <td>ddlovato</td>\n",
              "      <td>‚ùÑÔ∏è http://t.co/sHCFdPpGPa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>05/01/2015 00:06</td>\n",
              "      <td>5.518920e+17</td>\n",
              "      <td>und</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15985</td>\n",
              "      <td>10456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52541</th>\n",
              "      <td>52541</td>\n",
              "      <td>ddlovato</td>\n",
              "      <td>‚ù§Ô∏è‚ùÑÔ∏è‚úàÔ∏è http://t.co/ixmB5lv17Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>05/01/2015 00:02</td>\n",
              "      <td>5.518910e+17</td>\n",
              "      <td>und</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16193</td>\n",
              "      <td>10822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       index    author                                            content  \\\n",
              "52537  52537  ddlovato               Life couldn't be better right now. üòä   \n",
              "52538  52538  ddlovato  First Monday back in action. I'd say 21.6 mile...   \n",
              "52539  52539  ddlovato  Crime shows, buddy, snuggles = the perfect Sun...   \n",
              "52540  52540  ddlovato                          ‚ùÑÔ∏è http://t.co/sHCFdPpGPa   \n",
              "52541  52541  ddlovato                      ‚ù§Ô∏è‚ùÑÔ∏è‚úàÔ∏è http://t.co/ixmB5lv17Z   \n",
              "\n",
              "      country         date_time            id language  latitude  longitude  \\\n",
              "52537     NaN  06/01/2015 23:10  5.526030e+17       en       NaN        NaN   \n",
              "52538     NaN  06/01/2015 02:17  5.522880e+17       en       NaN        NaN   \n",
              "52539     NaN  05/01/2015 03:42  5.519470e+17       en       NaN        NaN   \n",
              "52540     NaN  05/01/2015 00:06  5.518920e+17      und       NaN        NaN   \n",
              "52541     NaN  05/01/2015 00:02  5.518910e+17      und       NaN        NaN   \n",
              "\n",
              "       number_of_likes  number_of_shares  \n",
              "52537            32799             23796  \n",
              "52538            21709             12511  \n",
              "52539            25269             15583  \n",
              "52540            15985             10456  \n",
              "52541            16193             10822  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#displaying the last 5 tweets from the data\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f19ac9fd",
      "metadata": {
        "id": "f19ac9fd",
        "outputId": "5907bd16-756d-414c-f32f-eed6801f1e5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    @barackobama Thank you for your incredible gra...\n",
              "2                  Life goals. https://t.co/XIn1qKMKQl\n",
              "3              Me right now üôèüèª https://t.co/gW55C1wrwd\n",
              "Name: content, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#inspecting a single row of the text column\n",
        "df['content'][1:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d9642ad5",
      "metadata": {
        "id": "d9642ad5"
      },
      "outputs": [],
      "source": [
        "#selecting columns of interest only\n",
        "text_data=df[['author','content','date_time','number_of_shares']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "21106dcb",
      "metadata": {
        "id": "21106dcb",
        "outputId": "69739b45-b773-45e3-b434-30de3cddac1e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>date_time</th>\n",
              "      <th>number_of_shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
              "      <td>12/01/2017 19:52</td>\n",
              "      <td>3472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>@barackobama Thank you for your incredible gra...</td>\n",
              "      <td>11/01/2017 08:38</td>\n",
              "      <td>1380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
              "      <td>11/01/2017 02:52</td>\n",
              "      <td>2387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
              "      <td>11/01/2017 02:44</td>\n",
              "      <td>2458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
              "      <td>10/01/2017 05:22</td>\n",
              "      <td>4655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      author                                            content  \\\n",
              "0  katyperry  Is history repeating itself...?#DONTNORMALIZEH...   \n",
              "1  katyperry  @barackobama Thank you for your incredible gra...   \n",
              "2  katyperry                Life goals. https://t.co/XIn1qKMKQl   \n",
              "3  katyperry            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
              "4  katyperry  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
              "\n",
              "          date_time  number_of_shares  \n",
              "0  12/01/2017 19:52              3472  \n",
              "1  11/01/2017 08:38              1380  \n",
              "2  11/01/2017 02:52              2387  \n",
              "3  11/01/2017 02:44              2458  \n",
              "4  10/01/2017 05:22              4655  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eadb2270",
      "metadata": {
        "id": "eadb2270"
      },
      "source": [
        "## Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "93986a36",
      "metadata": {
        "id": "93986a36",
        "outputId": "8451c65f-85a7-44c0-c490-29dc089ebd65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>date_time</th>\n",
              "      <th>number_of_shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
              "      <td>12/01/2017 19:52</td>\n",
              "      <td>3472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>@barackobama Thank you for your incredible gra...</td>\n",
              "      <td>11/01/2017 08:38</td>\n",
              "      <td>1380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
              "      <td>11/01/2017 02:52</td>\n",
              "      <td>2387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
              "      <td>11/01/2017 02:44</td>\n",
              "      <td>2458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
              "      <td>10/01/2017 05:22</td>\n",
              "      <td>4655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52537</th>\n",
              "      <td>ddlovato</td>\n",
              "      <td>Life couldn't be better right now. üòä</td>\n",
              "      <td>06/01/2015 23:10</td>\n",
              "      <td>23796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52538</th>\n",
              "      <td>ddlovato</td>\n",
              "      <td>First Monday back in action. I'd say 21.6 mile...</td>\n",
              "      <td>06/01/2015 02:17</td>\n",
              "      <td>12511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52539</th>\n",
              "      <td>ddlovato</td>\n",
              "      <td>Crime shows, buddy, snuggles = the perfect Sun...</td>\n",
              "      <td>05/01/2015 03:42</td>\n",
              "      <td>15583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52540</th>\n",
              "      <td>ddlovato</td>\n",
              "      <td>‚ùÑÔ∏è http://t.co/sHCFdPpGPa</td>\n",
              "      <td>05/01/2015 00:06</td>\n",
              "      <td>10456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52541</th>\n",
              "      <td>ddlovato</td>\n",
              "      <td>‚ù§Ô∏è‚ùÑÔ∏è‚úàÔ∏è http://t.co/ixmB5lv17Z</td>\n",
              "      <td>05/01/2015 00:02</td>\n",
              "      <td>10822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52425 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          author                                            content  \\\n",
              "0      katyperry  Is history repeating itself...?#DONTNORMALIZEH...   \n",
              "1      katyperry  @barackobama Thank you for your incredible gra...   \n",
              "2      katyperry                Life goals. https://t.co/XIn1qKMKQl   \n",
              "3      katyperry            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
              "4      katyperry  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
              "...          ...                                                ...   \n",
              "52537   ddlovato               Life couldn't be better right now. üòä   \n",
              "52538   ddlovato  First Monday back in action. I'd say 21.6 mile...   \n",
              "52539   ddlovato  Crime shows, buddy, snuggles = the perfect Sun...   \n",
              "52540   ddlovato                          ‚ùÑÔ∏è http://t.co/sHCFdPpGPa   \n",
              "52541   ddlovato                      ‚ù§Ô∏è‚ùÑÔ∏è‚úàÔ∏è http://t.co/ixmB5lv17Z   \n",
              "\n",
              "              date_time  number_of_shares  \n",
              "0      12/01/2017 19:52              3472  \n",
              "1      11/01/2017 08:38              1380  \n",
              "2      11/01/2017 02:52              2387  \n",
              "3      11/01/2017 02:44              2458  \n",
              "4      10/01/2017 05:22              4655  \n",
              "...                 ...               ...  \n",
              "52537  06/01/2015 23:10             23796  \n",
              "52538  06/01/2015 02:17             12511  \n",
              "52539  05/01/2015 03:42             15583  \n",
              "52540  05/01/2015 00:06             10456  \n",
              "52541  05/01/2015 00:02             10822  \n",
              "\n",
              "[52425 rows x 4 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# removing duplicates from the text column\n",
        "text_data.drop_duplicates('content',keep='first')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "42c289e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "#remove username and links\n",
        "def clean_text(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    text = url_pattern.sub(r'', text)\n",
        "    return text.strip()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d3a9887d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>date_time</th>\n",
              "      <th>number_of_shares</th>\n",
              "      <th>Processed_Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
              "      <td>12/01/2017 19:52</td>\n",
              "      <td>3472</td>\n",
              "      <td>Is history repeating itself...?#DONTNORMALIZEHATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>@barackobama Thank you for your incredible gra...</td>\n",
              "      <td>11/01/2017 08:38</td>\n",
              "      <td>1380</td>\n",
              "      <td>@barackobama Thank you for your incredible gra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
              "      <td>11/01/2017 02:52</td>\n",
              "      <td>2387</td>\n",
              "      <td>Life goals.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
              "      <td>11/01/2017 02:44</td>\n",
              "      <td>2458</td>\n",
              "      <td>Me right now üôèüèª</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
              "      <td>10/01/2017 05:22</td>\n",
              "      <td>4655</td>\n",
              "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      author                                            content  \\\n",
              "0  katyperry  Is history repeating itself...?#DONTNORMALIZEH...   \n",
              "1  katyperry  @barackobama Thank you for your incredible gra...   \n",
              "2  katyperry                Life goals. https://t.co/XIn1qKMKQl   \n",
              "3  katyperry            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
              "4  katyperry  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
              "\n",
              "          date_time  number_of_shares  \\\n",
              "0  12/01/2017 19:52              3472   \n",
              "1  11/01/2017 08:38              1380   \n",
              "2  11/01/2017 02:52              2387   \n",
              "3  11/01/2017 02:44              2458   \n",
              "4  10/01/2017 05:22              4655   \n",
              "\n",
              "                                    Processed_Tweets  \n",
              "0  Is history repeating itself...?#DONTNORMALIZEHATE  \n",
              "1  @barackobama Thank you for your incredible gra...  \n",
              "2                                        Life goals.  \n",
              "3                                    Me right now üôèüèª  \n",
              "4        SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data['Processed_Tweets'] =text_data['content'].apply(clean_text)\n",
        "text_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7344b5b4",
      "metadata": {
        "id": "7344b5b4",
        "outputId": "791db454-3bc5-4c0e-900a-8f9a560bf056"
      },
      "outputs": [],
      "source": [
        "#remove links and urls\n",
        "# def remove_usernames_links(content):\n",
        "#     content=re.sub('http[^\\s]+','',content)\n",
        "#     return content\n",
        "    \n",
        "\n",
        "# text_data['Processed_Tweets'] =text_data['content'].apply(remove_usernames_links)\n",
        "# text_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d963d306",
      "metadata": {
        "id": "d963d306",
        "outputId": "b8b6355d-5ab2-49bd-ca58-6ed592c015ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Is history repeating itself...?#DONTNORMALIZEHATE\n",
              "1    @barackobama Thank you for your incredible gra...\n",
              "2                                          Life goals.\n",
              "3                                      Me right now üôèüèª\n",
              "Name: Processed_Tweets, dtype: object"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data['Processed_Tweets'][0:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "9b40a9b0",
      "metadata": {
        "id": "9b40a9b0",
        "outputId": "2a59401d-6648-46b3-eda2-432f4c15d3af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove punctuation from the text column\n",
        "import string\n",
        "import html\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "53dd98df",
      "metadata": {
        "id": "53dd98df",
        "outputId": "478547f4-52c2-4482-b28e-a86168c5410a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>date_time</th>\n",
              "      <th>number_of_shares</th>\n",
              "      <th>Processed_Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
              "      <td>12/01/2017 19:52</td>\n",
              "      <td>3472</td>\n",
              "      <td>Is history repeating itselfDONTNORMALIZEHATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>@barackobama Thank you for your incredible gra...</td>\n",
              "      <td>11/01/2017 08:38</td>\n",
              "      <td>1380</td>\n",
              "      <td>barackobama Thank you for your incredible grac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
              "      <td>11/01/2017 02:52</td>\n",
              "      <td>2387</td>\n",
              "      <td>Life goals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
              "      <td>11/01/2017 02:44</td>\n",
              "      <td>2458</td>\n",
              "      <td>Me right now üôèüèª</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
              "      <td>10/01/2017 05:22</td>\n",
              "      <td>4655</td>\n",
              "      <td>SISTERS ARE DOIN IT FOR THEMSELVES üôåüèªüí™üèª‚ù§Ô∏è</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      author                                            content  \\\n",
              "0  katyperry  Is history repeating itself...?#DONTNORMALIZEH...   \n",
              "1  katyperry  @barackobama Thank you for your incredible gra...   \n",
              "2  katyperry                Life goals. https://t.co/XIn1qKMKQl   \n",
              "3  katyperry            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
              "4  katyperry  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
              "\n",
              "          date_time  number_of_shares  \\\n",
              "0  12/01/2017 19:52              3472   \n",
              "1  11/01/2017 08:38              1380   \n",
              "2  11/01/2017 02:52              2387   \n",
              "3  11/01/2017 02:44              2458   \n",
              "4  10/01/2017 05:22              4655   \n",
              "\n",
              "                                    Processed_Tweets  \n",
              "0       Is history repeating itselfDONTNORMALIZEHATE  \n",
              "1  barackobama Thank you for your incredible grac...  \n",
              "2                                         Life goals  \n",
              "3                                    Me right now üôèüèª  \n",
              "4          SISTERS ARE DOIN IT FOR THEMSELVES üôåüèªüí™üèª‚ù§Ô∏è  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def remove_punctuation(content):\n",
        "    no_punct=[words for words in content if words not in string.punctuation]\n",
        "    words_wo_punct=''.join(no_punct)\n",
        "    return words_wo_punct\n",
        "text_data['Processed_Tweets']=text_data['Processed_Tweets'].apply(lambda x: remove_punctuation(x))\n",
        "text_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "5a3b6609",
      "metadata": {
        "id": "5a3b6609",
        "outputId": "d6e76a28-884a-433f-c05f-8b90717416d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Is history repeating itselfDONTNORMALIZEHATE\n",
              "1    barackobama Thank you for your incredible grac...\n",
              "2                                           Life goals\n",
              "3                                      Me right now üôèüèª\n",
              "4            SISTERS ARE DOIN IT FOR THEMSELVES üôåüèªüí™üèª‚ù§Ô∏è\n",
              "5    happy 96th gma fourmoreyears üéà  LACMA Los Ange...\n",
              "6                               Kyoto Japan \\r\\n1 5 17\n",
              "7                                  üáØüáµ  Sanrio Puroland\n",
              "8               2017 resolution to embody authenticity\n",
              "9                                              sisters\n",
              "Name: Processed_Tweets, dtype: object"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data['Processed_Tweets'][0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ca7412b0",
      "metadata": {
        "id": "ca7412b0",
        "outputId": "c8178478-b698-4023-d7ac-bec7e24cf888"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>date_time</th>\n",
              "      <th>number_of_shares</th>\n",
              "      <th>Processed_Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
              "      <td>12/01/2017 19:52</td>\n",
              "      <td>3472</td>\n",
              "      <td>Is history repeating itselfDONTNORMALIZEHATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>@barackobama Thank you for your incredible gra...</td>\n",
              "      <td>11/01/2017 08:38</td>\n",
              "      <td>1380</td>\n",
              "      <td>barackobama Thank you for your incredible grac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
              "      <td>11/01/2017 02:52</td>\n",
              "      <td>2387</td>\n",
              "      <td>Life goals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
              "      <td>11/01/2017 02:44</td>\n",
              "      <td>2458</td>\n",
              "      <td>Me right now üôèüèª</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
              "      <td>10/01/2017 05:22</td>\n",
              "      <td>4655</td>\n",
              "      <td>SISTERS ARE DOIN IT FOR THEMSELVES üôåüèªüí™üèª‚ù§Ô∏è</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      author                                            content  \\\n",
              "0  katyperry  Is history repeating itself...?#DONTNORMALIZEH...   \n",
              "1  katyperry  @barackobama Thank you for your incredible gra...   \n",
              "2  katyperry                Life goals. https://t.co/XIn1qKMKQl   \n",
              "3  katyperry            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
              "4  katyperry  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
              "\n",
              "          date_time  number_of_shares  \\\n",
              "0  12/01/2017 19:52              3472   \n",
              "1  11/01/2017 08:38              1380   \n",
              "2  11/01/2017 02:52              2387   \n",
              "3  11/01/2017 02:44              2458   \n",
              "4  10/01/2017 05:22              4655   \n",
              "\n",
              "                                    Processed_Tweets  \n",
              "0       Is history repeating itselfDONTNORMALIZEHATE  \n",
              "1  barackobama Thank you for your incredible grac...  \n",
              "2                                         Life goals  \n",
              "3                                    Me right now üôèüèª  \n",
              "4          SISTERS ARE DOIN IT FOR THEMSELVES üôåüèªüí™üèª‚ù§Ô∏è  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# remove numbers \n",
        "def remove_numbers(Processed_Tweets):\n",
        "    Processed_Tweets=re.sub(r'\\d','',Processed_Tweets)\n",
        "    return Processed_Tweets\n",
        "text_data['Processed_Tweets']=text_data['Processed_Tweets'].apply(lambda x: remove_numbers(x))\n",
        "text_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a34c196d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Is history repeating itselfDONTNORMALIZEHATE\n",
              "1    barackobama Thank you for your incredible grac...\n",
              "2                                           Life goals\n",
              "3                                      Me right now üôèüèª\n",
              "4            SISTERS ARE DOIN IT FOR THEMSELVES üôåüèªüí™üèª‚ù§Ô∏è\n",
              "5    happy th gma fourmoreyears üéà  LACMA Los Angele...\n",
              "6                                   Kyoto Japan \\r\\n  \n",
              "7                                  üáØüáµ  Sanrio Puroland\n",
              "8                    resolution to embody authenticity\n",
              "9                                              sisters\n",
              "Name: Processed_Tweets, dtype: object"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data['Processed_Tweets'][0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "68a7f273",
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range (len(text_data['Processed_Tweets'])):\n",
        "    \n",
        "    x = text_data['Processed_Tweets'][i].replace(\"\\n\",\" \").replace(\"\\r\",\" \") #cleaning newline ‚Äú\\n‚Äù from the tweets\n",
        "    text_data['Processed_Tweets'][i] = html.unescape(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "44112593",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Is history repeating itselfDONTNORMALIZEHATE\n",
              "1    barackobama Thank you for your incredible grac...\n",
              "2                                           Life goals\n",
              "3                                      Me right now üôèüèª\n",
              "4            SISTERS ARE DOIN IT FOR THEMSELVES üôåüèªüí™üèª‚ù§Ô∏è\n",
              "5    happy th gma fourmoreyears üéà  LACMA Los Angele...\n",
              "6                                     Kyoto Japan     \n",
              "7                                  üáØüáµ  Sanrio Puroland\n",
              "8                    resolution to embody authenticity\n",
              "9                                              sisters\n",
              "Name: Processed_Tweets, dtype: object"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data['Processed_Tweets'][0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ee4e348e",
      "metadata": {
        "id": "ee4e348e",
        "outputId": "74c74c81-7d9c-42c4-8ac7-f1f8687d898b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>date_time</th>\n",
              "      <th>number_of_shares</th>\n",
              "      <th>Processed_Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
              "      <td>12/01/2017 19:52</td>\n",
              "      <td>3472</td>\n",
              "      <td>Is history repeating itselfDONTNORMALIZEHATE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>@barackobama Thank you for your incredible gra...</td>\n",
              "      <td>11/01/2017 08:38</td>\n",
              "      <td>1380</td>\n",
              "      <td>barackobama Thank you for your incredible grac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
              "      <td>11/01/2017 02:52</td>\n",
              "      <td>2387</td>\n",
              "      <td>Life goals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
              "      <td>11/01/2017 02:44</td>\n",
              "      <td>2458</td>\n",
              "      <td>Me right now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
              "      <td>10/01/2017 05:22</td>\n",
              "      <td>4655</td>\n",
              "      <td>SISTERS ARE DOIN IT FOR THEMSELVES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      author                                            content  \\\n",
              "0  katyperry  Is history repeating itself...?#DONTNORMALIZEH...   \n",
              "1  katyperry  @barackobama Thank you for your incredible gra...   \n",
              "2  katyperry                Life goals. https://t.co/XIn1qKMKQl   \n",
              "3  katyperry            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
              "4  katyperry  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
              "\n",
              "          date_time  number_of_shares  \\\n",
              "0  12/01/2017 19:52              3472   \n",
              "1  11/01/2017 08:38              1380   \n",
              "2  11/01/2017 02:52              2387   \n",
              "3  11/01/2017 02:44              2458   \n",
              "4  10/01/2017 05:22              4655   \n",
              "\n",
              "                                    Processed_Tweets  \n",
              "0       Is history repeating itselfDONTNORMALIZEHATE  \n",
              "1  barackobama Thank you for your incredible grac...  \n",
              "2                                         Life goals  \n",
              "3                                      Me right now   \n",
              "4                SISTERS ARE DOIN IT FOR THEMSELVES   "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#remove emojis\n",
        "def deEmojify(inputString):\n",
        "    return inputString.encode('ascii','ignore').decode('ascii')\n",
        "text_data['Processed_Tweets']=text_data['Processed_Tweets'].apply(lambda s:deEmojify(s))\n",
        "text_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "cc1ab69a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Is history repeating itselfDONTNORMALIZEHATE\n",
              "1    barackobama Thank you for your incredible grac...\n",
              "2                                           Life goals\n",
              "3                                        Me right now \n",
              "4                  SISTERS ARE DOIN IT FOR THEMSELVES \n",
              "5    happy th gma fourmoreyears   LACMA Los Angeles...\n",
              "6                                     Kyoto Japan     \n",
              "7                                      Sanrio Puroland\n",
              "8                    resolution to embody authenticity\n",
              "9                                              sisters\n",
              "Name: Processed_Tweets, dtype: object"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data['Processed_Tweets'][0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "cffcdd2b",
      "metadata": {
        "id": "cffcdd2b",
        "outputId": "27f06b5a-c508-4a0e-c4d8-d53980044b4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>date_time</th>\n",
              "      <th>number_of_shares</th>\n",
              "      <th>Processed_Tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Is history repeating itself...?#DONTNORMALIZEH...</td>\n",
              "      <td>12/01/2017 19:52</td>\n",
              "      <td>3472</td>\n",
              "      <td>is history repeating itselfdontnormalizehate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>@barackobama Thank you for your incredible gra...</td>\n",
              "      <td>11/01/2017 08:38</td>\n",
              "      <td>1380</td>\n",
              "      <td>barackobama thank you for your incredible grac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Life goals. https://t.co/XIn1qKMKQl</td>\n",
              "      <td>11/01/2017 02:52</td>\n",
              "      <td>2387</td>\n",
              "      <td>life goals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>Me right now üôèüèª https://t.co/gW55C1wrwd</td>\n",
              "      <td>11/01/2017 02:44</td>\n",
              "      <td>2458</td>\n",
              "      <td>me right now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>katyperry</td>\n",
              "      <td>SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...</td>\n",
              "      <td>10/01/2017 05:22</td>\n",
              "      <td>4655</td>\n",
              "      <td>sisters are doin it for themselves</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      author                                            content  \\\n",
              "0  katyperry  Is history repeating itself...?#DONTNORMALIZEH...   \n",
              "1  katyperry  @barackobama Thank you for your incredible gra...   \n",
              "2  katyperry                Life goals. https://t.co/XIn1qKMKQl   \n",
              "3  katyperry            Me right now üôèüèª https://t.co/gW55C1wrwd   \n",
              "4  katyperry  SISTERS ARE DOIN' IT FOR THEMSELVES! üôåüèªüí™üèª‚ù§Ô∏è ht...   \n",
              "\n",
              "          date_time  number_of_shares  \\\n",
              "0  12/01/2017 19:52              3472   \n",
              "1  11/01/2017 08:38              1380   \n",
              "2  11/01/2017 02:52              2387   \n",
              "3  11/01/2017 02:44              2458   \n",
              "4  10/01/2017 05:22              4655   \n",
              "\n",
              "                                    Processed_Tweets  \n",
              "0       is history repeating itselfdontnormalizehate  \n",
              "1  barackobama thank you for your incredible grac...  \n",
              "2                                         life goals  \n",
              "3                                      me right now   \n",
              "4                sisters are doin it for themselves   "
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#convert cleaned text to lower case\n",
        "text_data['Processed_Tweets']=text_data['Processed_Tweets'].str.lower()\n",
        "text_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "52d74536",
      "metadata": {
        "id": "52d74536",
        "outputId": "fa347582-10a3-4372-b5e9-9cc03d758d8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         is history repeating itselfdontnormalizehate\n",
              "1    barackobama thank you for your incredible grac...\n",
              "2                                           life goals\n",
              "3                                        me right now \n",
              "4                  sisters are doin it for themselves \n",
              "Name: Processed_Tweets, dtype: object"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2=text_data['Processed_Tweets']\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc93e632",
      "metadata": {
        "id": "bc93e632"
      },
      "outputs": [],
      "source": [
        "# df2.to_csv('ner_data.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e2ecdf6",
      "metadata": {
        "id": "9e2ecdf6",
        "outputId": "0746a2ea-11d6-453f-fb2b-c03260f6ccda"
      },
      "outputs": [],
      "source": [
        "# panda=pd.read_csv('ner_data.csv')\n",
        "# panda=panda.dropna(how='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d9c3f45",
      "metadata": {},
      "outputs": [],
      "source": [
        "# panda.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f8b7da23",
      "metadata": {
        "id": "f8b7da23",
        "outputId": "6e446d61-29b1-435f-8335-d9f08d63922f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/mac/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /Users/mac/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# importing libraries for preprocessing\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# from nltk.stem.porter import PorterStemmer\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import os\n",
        "import string\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "# %matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1f3f25b1",
      "metadata": {
        "id": "1f3f25b1"
      },
      "outputs": [],
      "source": [
        "eng_stop_words=list(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "151edbf8",
      "metadata": {},
      "outputs": [],
      "source": [
        "def PreprocessedTweets(content):\n",
        "    # Initialize the lemmatizer\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    \n",
        "    # Tokenize the tweet\n",
        "    tokens = word_tokenize(content)\n",
        "    \n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "    \n",
        "    # Lemmatize tokens\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    \n",
        "    # Reconstruct the tweet\n",
        "    cleaned_tweet = ' '.join(tokens)\n",
        "    return cleaned_tweet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b2d5466d",
      "metadata": {
        "id": "b2d5466d",
        "outputId": "30e72541-b900-4ee1-cb73-5efc66a91cd6"
      },
      "outputs": [],
      "source": [
        "text_data['Processed_Tweets']=text_data['Processed_Tweets'].apply(PreprocessedTweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "92e2cb8d",
      "metadata": {
        "id": "92e2cb8d",
        "outputId": "8ff0879c-23a6-4090-fbc6-a7229b67546a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0            history repeating itselfdontnormalizehate\n",
              "1    barackobama thank incredible grace leadership ...\n",
              "2                                            life goal\n",
              "3                                                right\n",
              "4                                          sister doin\n",
              "5    happy th gma fourmoreyears lacma los angeles c...\n",
              "6                                          kyoto japan\n",
              "7                                      sanrio puroland\n",
              "8                       resolution embody authenticity\n",
              "9                                               sister\n",
              "Name: Processed_Tweets, dtype: object"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_data['Processed_Tweets'][0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2911454d",
      "metadata": {
        "id": "2911454d"
      },
      "source": [
        "## Analyzing Text statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "55e3bd00",
      "metadata": {
        "id": "55e3bd00",
        "outputId": "3e1918bb-b4e8-404d-cc6f-3792390aa829"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "`np.string_` was removed in the NumPy 2.0 release. Use `np.bytes_` instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#number of characters present in each sentence\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtext_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProcessed_Tweets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/pandas/plotting/_core.py:129\u001b[0m, in \u001b[0;36mhist_series\u001b[0;34m(self, by, ax, grid, xlabelsize, xrot, ylabelsize, yrot, figsize, bins, backend, legend, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mDraw histogram of the input series using matplotlib.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;124;03m    >>> hist = ser.groupby(level=0).hist()\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m plot_backend \u001b[38;5;241m=\u001b[39m _get_plot_backend(backend)\n\u001b[0;32m--> 129\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mplot_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxlabelsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxlabelsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxrot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxrot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mylabelsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mylabelsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43myrot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myrot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfigsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/pandas/plotting/_matplotlib/hist.py:454\u001b[0m, in \u001b[0;36mhist_series\u001b[0;34m(self, by, ax, grid, xlabelsize, xrot, ylabelsize, yrot, figsize, bins, legend, **kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m legend:\n\u001b[1;32m    453\u001b[0m     kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m--> 454\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m legend:\n\u001b[1;32m    456\u001b[0m     ax\u001b[38;5;241m.\u001b[39mlegend()\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/axes/_axes.py:6922\u001b[0m, in \u001b[0;36mAxes.hist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6920\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6921\u001b[0m     height \u001b[38;5;241m=\u001b[39m top\n\u001b[0;32m-> 6922\u001b[0m bars \u001b[38;5;241m=\u001b[39m \u001b[43m_barfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mboffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6923\u001b[0m \u001b[43m                \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcenter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   6924\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mbottom_kwarg\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6925\u001b[0m patches\u001b[38;5;241m.\u001b[39mappend(bars)\n\u001b[1;32m   6926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stacked:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/axes/_axes.py:2538\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# horizontal\u001b[39;00m\n\u001b[1;32m   2537\u001b[0m         r\u001b[38;5;241m.\u001b[39msticky_edges\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mappend(l)\n\u001b[0;32m-> 2538\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2539\u001b[0m     patches\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/axes/_base.py:2384\u001b[0m, in \u001b[0;36m_AxesBase.add_patch\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2383\u001b[0m     p\u001b[38;5;241m.\u001b[39mset_clip_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[0;32m-> 2384\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_patch_limits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[1;32m   2386\u001b[0m p\u001b[38;5;241m.\u001b[39m_remove_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children\u001b[38;5;241m.\u001b[39mremove\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/axes/_base.py:2406\u001b[0m, in \u001b[0;36m_AxesBase._update_patch_limits\u001b[0;34m(self, patch)\u001b[0m\n\u001b[1;32m   2403\u001b[0m \u001b[38;5;66;03m# Get all vertices on the path\u001b[39;00m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;66;03m# Loop through each segment to get extrema for Bezier curve sections\u001b[39;00m\n\u001b[1;32m   2405\u001b[0m vertices \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2406\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcurve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_bezier\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimplify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   2407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Get distance along the curve of any extrema\u001b[39;49;00m\n\u001b[1;32m   2408\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdzeros\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcurve\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis_aligned_extrema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2409\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Calculate vertices of start, end and any extrema in between\u001b[39;49;00m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/path.py:437\u001b[0m, in \u001b[0;36mPath.iter_bezier\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m first_vert \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    436\u001b[0m prev_vert \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 437\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_segments\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfirst_vert\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMOVETO\u001b[49m\u001b[43m:\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/path.py:404\u001b[0m, in \u001b[0;36mPath.iter_segments\u001b[0;34m(self, transform, remove_nans, clip, snap, stroke_width, simplify, curves, sketch)\u001b[0m\n\u001b[1;32m    402\u001b[0m codes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(cleaned\u001b[38;5;241m.\u001b[39mcodes)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m curr_vertices, code \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(vertices, codes):\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSTOP\u001b[49m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     extra_vertices \u001b[38;5;241m=\u001b[39m NUM_VERTICES_FOR_CODE[code] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/numpy/_core/_internal.py:872\u001b[0m, in \u001b[0;36marray_ufunc_errmsg_formatter\u001b[0;34m(dummy, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_ufunc_errmsg_formatter\u001b[39m(dummy, ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    871\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Format the error message for when __array_ufunc__ gives up. \"\"\"\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m     args_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{!r}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    873\u001b[0m                             [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k, v)\n\u001b[1;32m    874\u001b[0m                              \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()])\n\u001b[1;32m    875\u001b[0m     args \u001b[38;5;241m=\u001b[39m inputs \u001b[38;5;241m+\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m, ())\n\u001b[1;32m    876\u001b[0m     types_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/numpy/_core/_internal.py:872\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_ufunc_errmsg_formatter\u001b[39m(dummy, ufunc, method, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    871\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Format the error message for when __array_ufunc__ gives up. \"\"\"\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m     args_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{!r}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m inputs] \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m    873\u001b[0m                             [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k, v)\n\u001b[1;32m    874\u001b[0m                              \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()])\n\u001b[1;32m    875\u001b[0m     args \u001b[38;5;241m=\u001b[39m inputs \u001b[38;5;241m+\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m, ())\n\u001b[1;32m    876\u001b[0m     types_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(arg)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/numpy/core/arrayprint.py:1475\u001b[0m, in \u001b[0;36m_array_repr_implementation\u001b[0;34m(arr, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1473\u001b[0m     class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1475\u001b[0m skipdtype \u001b[38;5;241m=\u001b[39m \u001b[43mdtype_is_implied\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m arr\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1477\u001b[0m prefix \u001b[38;5;241m=\u001b[39m class_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1478\u001b[0m suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipdtype \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/numpy/core/arrayprint.py:1424\u001b[0m, in \u001b[0;36mdtype_is_implied\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdtype_is_implied\u001b[39m(dtype):\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;124;03m    Determine if the given dtype is implied by the representation of its values.\u001b[39;00m\n\u001b[1;32m   1402\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;124;03m    array([1, 2, 3], dtype=int8)\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1424\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _format_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegacy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m113\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m bool_:\n\u001b[1;32m   1426\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/numpy/core/_dtype.py:46\u001b[0m, in \u001b[0;36m__repr__\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(dtype):\n\u001b[0;32m---> 46\u001b[0m     arg_str \u001b[38;5;241m=\u001b[39m \u001b[43m_construction_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_align\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39misalignedstruct:\n\u001b[1;32m     48\u001b[0m         arg_str \u001b[38;5;241m=\u001b[39m arg_str \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, align=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/numpy/core/_dtype.py:100\u001b[0m, in \u001b[0;36m_construction_repr\u001b[0;34m(dtype, include_align, short)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _subarray_str(dtype)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_scalar_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshort\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/numpy/core/_dtype.py:117\u001b[0m, in \u001b[0;36m_scalar_str\u001b[0;34m(dtype, short)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# The object reference may be different sizes on different\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# platforms, so it should never include the itemsize here.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring_\u001b[49m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _isunsized(dtype):\n\u001b[1;32m    119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/numpy/__init__.py:397\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m    396\u001b[0m use_hugepage \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNUMPY_MADVISE_HUGEPAGE\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinux\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m use_hugepage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;66;03m# If there is an issue with parsing the kernel version,\u001b[39;00m\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;66;03m# set use_hugepages to 0. Usage of LooseVersion will handle\u001b[39;00m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# the kernel version parsing better, but avoided since it\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# will increase the import time. See: #16679 for related discussion.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         use_hugepage \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31mAttributeError\u001b[0m: `np.string_` was removed in the NumPy 2.0 release. Use `np.bytes_` instead."
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _draw_all_if_interactive at 0x11c911bc0> (for post_execute), with arguments args (),kwargs {}:\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "object __array__ method not producing an array",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/pyplot.py:197\u001b[0m, in \u001b[0;36m_draw_all_if_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_draw_all_if_interactive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m matplotlib\u001b[38;5;241m.\u001b[39mis_interactive():\n\u001b[0;32m--> 197\u001b[0m         \u001b[43mdraw_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/_pylab_helpers.py:132\u001b[0m, in \u001b[0;36mGcf.draw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mstale:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/backend_bases.py:1893\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   1892\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> 1893\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:388\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    387\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/figure.py:3153\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3150\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m-> 3153\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3154\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3155\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/patches.py:588\u001b[0m, in \u001b[0;36mPatch.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    586\u001b[0m tpath \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform_path_non_affine(path)\n\u001b[1;32m    587\u001b[0m affine \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_paths_with_artist_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Work around a bug in the PDF and SVG renderers, which\u001b[39;49;00m\n\u001b[1;32m    592\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# do not draw the hatches if the facecolor is fully\u001b[39;49;00m\n\u001b[1;32m    593\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# transparent, but do if it is None.\u001b[39;49;00m\n\u001b[1;32m    594\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/patches.py:573\u001b[0m, in \u001b[0;36mPatch._draw_paths_with_artist_properties\u001b[0;34m(self, renderer, draw_path_args_list)\u001b[0m\n\u001b[1;32m    570\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m PathEffectRenderer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path_effects(), renderer)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m draw_path_args \u001b[38;5;129;01min\u001b[39;00m draw_path_args_list:\n\u001b[0;32m--> 573\u001b[0m     \u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdraw_path_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m gc\u001b[38;5;241m.\u001b[39mrestore()\n\u001b[1;32m    576\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:132\u001b[0m, in \u001b[0;36mRendererAgg.draw_path\u001b[0;34m(self, gc, path, transform, rgbFace)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgbFace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         cant_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[0;31mValueError\u001b[0m: object __array__ method not producing an array"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "object __array__ method not producing an array",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/IPython/core/formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    345\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/IPython/core/pylabtools.py:170\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    168\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 170\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/backend_bases.py:2193\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2190\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2191\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2192\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2193\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2194\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2195\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2196\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2197\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2198\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2199\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2201\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/backend_bases.py:2043\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2041\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2042\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2046\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:497\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:445\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    447\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    448\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:388\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    387\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 388\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/figure.py:3153\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3150\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m-> 3153\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3154\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3155\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/patches.py:588\u001b[0m, in \u001b[0;36mPatch.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    586\u001b[0m tpath \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform_path_non_affine(path)\n\u001b[1;32m    587\u001b[0m affine \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_paths_with_artist_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Work around a bug in the PDF and SVG renderers, which\u001b[39;49;00m\n\u001b[1;32m    592\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# do not draw the hatches if the facecolor is fully\u001b[39;49;00m\n\u001b[1;32m    593\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# transparent, but do if it is None.\u001b[39;49;00m\n\u001b[1;32m    594\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/patches.py:573\u001b[0m, in \u001b[0;36mPatch._draw_paths_with_artist_properties\u001b[0;34m(self, renderer, draw_path_args_list)\u001b[0m\n\u001b[1;32m    570\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m PathEffectRenderer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path_effects(), renderer)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m draw_path_args \u001b[38;5;129;01min\u001b[39;00m draw_path_args_list:\n\u001b[0;32m--> 573\u001b[0m     \u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdraw_path_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m gc\u001b[38;5;241m.\u001b[39mrestore()\n\u001b[1;32m    576\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/Users/anaconda3/envs/NLP/lib/python3.11/site-packages/matplotlib/backends/backend_agg.py:132\u001b[0m, in \u001b[0;36mRendererAgg.draw_path\u001b[0;34m(self, gc, path, transform, rgbFace)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgbFace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m         cant_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[0;31mValueError\u001b[0m: object __array__ method not producing an array"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#number of characters present in each sentence\n",
        "text_data['Processed_Tweets'].str.len().hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad6e1527",
      "metadata": {
        "id": "ad6e1527"
      },
      "source": [
        "- We can see that for the preprocessed tweets, the number of characters range approximately between 0 to 140.\n",
        "- Majority of the sentences have 10-80 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f99c61a",
      "metadata": {
        "id": "4f99c61a"
      },
      "outputs": [],
      "source": [
        "# number of words appearing in each processed tweets\n",
        "def plot_word_number_histogram(text):\n",
        "    text.str.split().\\\n",
        "        map(lambda x: len(x)).\\\n",
        "        hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00957f99",
      "metadata": {
        "id": "00957f99",
        "outputId": "c57f9a04-033e-420d-b024-22f7d97ece64"
      },
      "outputs": [],
      "source": [
        "plot_word_number_histogram(text_data['Processed_Tweets'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66880d01",
      "metadata": {
        "id": "66880d01"
      },
      "source": [
        "- Number of words appearing in the processed tweets range between 2 to 20 words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64881463",
      "metadata": {
        "id": "64881463"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a382954e",
      "metadata": {
        "id": "a382954e"
      },
      "outputs": [],
      "source": [
        "# Analyzing the stop words removed from the original tweets\n",
        "def plot_top_stopwords_barchart(text):\n",
        "    stop=set(stopwords.words('english'))\n",
        "    \n",
        "    new= text.str.split()\n",
        "    new=new.values.tolist()\n",
        "    corpus=[word for i in new for word in i]\n",
        "    from collections import defaultdict\n",
        "    dic=defaultdict(int)\n",
        "    for word in corpus:\n",
        "        if word in stop:\n",
        "            dic[word]+=1\n",
        "            \n",
        "    top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
        "    x,y=zip(*top)\n",
        "    plt.bar(x,y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ee0c50",
      "metadata": {
        "id": "26ee0c50",
        "outputId": "16b1f378-8472-46ad-80fc-58f25fad6586"
      },
      "outputs": [],
      "source": [
        "plot_top_stopwords_barchart(text_data['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7201551b",
      "metadata": {
        "id": "7201551b"
      },
      "source": [
        "The most common stop word in the Text column was the, followed by to and a. The least in the top 10 common stop words is my."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb4c7cf",
      "metadata": {
        "id": "4fb4c7cf"
      },
      "outputs": [],
      "source": [
        "#Top non stop words\n",
        "import seaborn as sns\n",
        "from collections import  Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c71c656",
      "metadata": {
        "id": "3c71c656"
      },
      "outputs": [],
      "source": [
        "def plot_top_non_stopwords_barchart(text):\n",
        "    stop=set(stopwords.words('english'))\n",
        "    \n",
        "    new= text.str.split()\n",
        "    new=new.values.tolist()\n",
        "    corpus=[word for i in new for word in i]\n",
        "\n",
        "    counter=Counter(corpus)\n",
        "    most=counter.most_common()\n",
        "    x, y=[], []\n",
        "    for word,count in most[:20]:\n",
        "        #if (word not in stop):\n",
        "            x.append(word)\n",
        "            y.append(count)\n",
        "            \n",
        "    sns.barplot(x=y,y=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "782e444e",
      "metadata": {
        "id": "782e444e",
        "outputId": "54590479-b7ac-43f8-af55-b493fba992d4"
      },
      "outputs": [],
      "source": [
        "plot_top_non_stopwords_barchart(text_data['Processed_Tweets'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a75ae65",
      "metadata": {
        "id": "5a75ae65"
      },
      "source": [
        "- From the bar graph, we can see the top non-stopwords are love,u, thank and new."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d93cf180",
      "metadata": {
        "id": "d93cf180"
      },
      "source": [
        "## Ngram exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25783e3",
      "metadata": {
        "id": "b25783e3"
      },
      "outputs": [],
      "source": [
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fc3fb78",
      "metadata": {
        "id": "4fc3fb78"
      },
      "outputs": [],
      "source": [
        "def plot_top_ngrams_barchart(text, n=2):\n",
        "    #stop=set(stopwords.words('english'))\n",
        "\n",
        "    new= text.str.split()\n",
        "    new=new.values.tolist()\n",
        "    corpus=[word for i in new for word in i]\n",
        "\n",
        "    def _get_top_ngram(corpus, n=None):\n",
        "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
        "        bag_of_words = vec.transform(corpus)\n",
        "        sum_words = bag_of_words.sum(axis=0) \n",
        "        words_freq = [(word, sum_words[0, idx]) \n",
        "                      for word, idx in vec.vocabulary_.items()]\n",
        "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "        return words_freq[:10]\n",
        "\n",
        "    top_n_bigrams=_get_top_ngram(text,n)[:10]\n",
        "    x,y=map(list,zip(*top_n_bigrams))\n",
        "    sns.barplot(x=y,y=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54618dd",
      "metadata": {
        "id": "f54618dd",
        "outputId": "f775c719-1548-4e56-8e76-7af9e3302808"
      },
      "outputs": [],
      "source": [
        "plot_top_ngrams_barchart(text_data['Processed_Tweets'],2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a7e4223",
      "metadata": {
        "id": "1a7e4223"
      },
      "source": [
        "- Bigrams such as president obama,happy birthday,cant wait,last night dominate the processed tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a248b0dc",
      "metadata": {
        "id": "a248b0dc",
        "outputId": "455cb92c-144f-4af1-93b9-dec5eb5afb18"
      },
      "outputs": [],
      "source": [
        "# top trigrams\n",
        "plot_top_ngrams_barchart(text_data['Processed_Tweets'],3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96982eed",
      "metadata": {
        "id": "96982eed"
      },
      "source": [
        "From the plot, weekend hashtag project, cant wait see, hashtag game tweet etc., dominate the trigrams of processed tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6fab7fb",
      "metadata": {
        "id": "e6fab7fb"
      },
      "source": [
        "## Word Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37582b0a",
      "metadata": {
        "id": "37582b0a",
        "outputId": "c50960f9-8ad6-4a49-d76a-2b5fc89ee0c2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "wordcloud = WordCloud(max_words=300, width=1200, height=800, background_color='white',\n",
        "                        collocations=False).generate(\" \".join(text_data['Processed_Tweets']))\n",
        "plt.grid(None)\n",
        "plt.title(\"WordCloud of Top Tweets by US Celebrities\")\n",
        "plt.axis('off')\n",
        "plt.imshow(wordcloud)\n",
        "plt.savefig('word_cloud.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b703cd",
      "metadata": {
        "id": "56b703cd"
      },
      "outputs": [],
      "source": [
        "# save data into csv format\n",
        "text_data.to_csv('usceleb_tweets.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96b09393",
      "metadata": {
        "id": "96b09393"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv('usceleb_tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e0dfbe4",
      "metadata": {
        "id": "8e0dfbe4",
        "outputId": "91fcbc63-4cc5-40d4-d8fa-35c460c47ed0"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "069832de",
      "metadata": {
        "id": "069832de",
        "outputId": "935df7d7-10cb-4e17-b1ef-32a883fb21db"
      },
      "outputs": [],
      "source": [
        "#top 10 tweet locations\n",
        "top_tweet_shares=data.number_of_shares.value_counts().sort_values(ascending=False).head(10)\n",
        "top_tweet_shares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbca91c3",
      "metadata": {
        "id": "bbca91c3",
        "outputId": "3c619901-ae61-448b-dcc7-f829970ade63"
      },
      "outputs": [],
      "source": [
        "top_username=data.author.value_counts().head(20)\n",
        "top_username"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c7c28bc",
      "metadata": {
        "id": "8c7c28bc",
        "outputId": "5ed53bf3-086b-4550-d0e7-ced18c3d1de8"
      },
      "outputs": [],
      "source": [
        "#visualizing the top tweeters from kenya\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.title(\"Top 20 authors of the tweets\",fontsize=18,color='Red')\n",
        "sns.barplot(y=top_username.index,x=top_username,palette='Set2',orient='h')\n",
        "plt.savefig('top_20_us.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50f6e122",
      "metadata": {
        "id": "50f6e122"
      },
      "source": [
        "## TOPIC MODELLING USING LATENT DIRCHLET ALLOCATION (LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a685738",
      "metadata": {
        "id": "1a685738",
        "outputId": "54c4eaea-5f7f-4068-ca9d-39a53d00b557"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'de', 'use','e','nm','tx','nz','u','im','i','I','th','gma'])\n",
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        # deacc=True removes punctuations\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) \n",
        "             if word not in stop_words] for doc in texts]\n",
        "data_n = data.Processed_Tweets.values.tolist()\n",
        "data_words = list(sent_to_words(data_n))\n",
        "# remove stop words\n",
        "data_words = remove_stopwords(data_words)\n",
        "print(data_words[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1da51df",
      "metadata": {
        "id": "b1da51df",
        "outputId": "02a0c7d5-9fa7-412f-f779-5e9454b60a10"
      },
      "outputs": [],
      "source": [
        "data_words[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59dbc79f",
      "metadata": {
        "id": "59dbc79f",
        "outputId": "b2a540a2-b9ac-496d-d13f-b575f848f22f"
      },
      "outputs": [],
      "source": [
        "import gensim.corpora as corpora\n",
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_words)\n",
        "# Create Corpus\n",
        "texts = data_words\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "# View\n",
        "print(corpus[:1][0][:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deaf939f",
      "metadata": {
        "id": "deaf939f",
        "outputId": "5e886ed6-cf77-4cd6-e035-7306ab329781"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "# number of topics\n",
        "num_topics = 10\n",
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                            id2word=id2word,\n",
        "                                            num_topics=num_topics,\n",
        "                                            random_state=100,\n",
        "                                            update_every=1,\n",
        "                                            chunksize=100,\n",
        "                                            passes=10,\n",
        "                                            alpha=\"auto\")\n",
        "                                            \n",
        "                                        \n",
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b992fbf7",
      "metadata": {
        "id": "b992fbf7"
      },
      "outputs": [],
      "source": [
        "import pyLDAvis.gensim_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d734771",
      "metadata": {
        "id": "9d734771",
        "outputId": "e8e38668-f79a-47e6-b92c-1efcf2c1c2fc"
      },
      "outputs": [],
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis=pyLDAvis.gensim_models.prepare(lda_model,corpus,id2word,\n",
        "                              mds=\"mds\",R=30)\n",
        "vis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a573013d",
      "metadata": {
        "id": "a573013d"
      },
      "source": [
        "## SENTIMENT ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7f7b1fb",
      "metadata": {
        "id": "f7f7b1fb"
      },
      "outputs": [],
      "source": [
        "#!pip install better_profanity\n",
        "#!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "536d1cfb",
      "metadata": {
        "id": "536d1cfb",
        "outputId": "bc347a8c-b78f-407d-b854-a5b6268f1cec"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "sentiments = SentimentIntensityAnalyzer()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42210fa2",
      "metadata": {
        "id": "42210fa2"
      },
      "outputs": [],
      "source": [
        "list1 = []\n",
        "for i in data['Processed_Tweets']:\n",
        "    list1.append((sentiments.polarity_scores(str(i)))['compound'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7826b86",
      "metadata": {
        "id": "c7826b86"
      },
      "outputs": [],
      "source": [
        "data['sentiment'] = pd.Series(list1)\n",
        "\n",
        "def sentiment_category(sentiment):\n",
        "    label = ''\n",
        "    if(sentiment>0):\n",
        "        label = 'positive'\n",
        "    elif(sentiment == 0):\n",
        "        label = 'neutral'\n",
        "    else:\n",
        "        label = 'negative'\n",
        "    return(label)\n",
        "\n",
        "data['sentiment_category'] = data['sentiment'].apply(sentiment_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e924bad",
      "metadata": {
        "id": "3e924bad",
        "outputId": "72eac297-e271-4943-b28a-f88707dfc6fa"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a16f85c",
      "metadata": {
        "id": "7a16f85c",
        "outputId": "8f050597-03da-4dd6-f721-b25b2c77a5aa"
      },
      "outputs": [],
      "source": [
        "data['sentiment_category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da3efa19",
      "metadata": {
        "id": "da3efa19",
        "outputId": "b9d86cdc-e823-44ac-9376-90c0a3586ddb"
      },
      "outputs": [],
      "source": [
        "# visualizing the sentiments\n",
        "data['sentiment_category'].value_counts().plot(kind='barh')\n",
        "plt.savefig('sentiment.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf0c2caa",
      "metadata": {
        "id": "bf0c2caa",
        "outputId": "7efe4eac-fd65-49be-b476-213db83c84bc"
      },
      "outputs": [],
      "source": [
        "#inspecting positively classified sentiments\n",
        "data[data['sentiment_category']=='positive']['content'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15487fac",
      "metadata": {
        "id": "15487fac",
        "outputId": "0ba39c75-11b0-4a1a-beb2-529c295007c5"
      },
      "outputs": [],
      "source": [
        "# inspecting negatively classified sentiments\n",
        "data[data['sentiment_category']=='negative']['content'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de6709bf",
      "metadata": {
        "id": "de6709bf",
        "outputId": "3e5079fd-7a9b-4e6c-b11e-9ee105fb91b3"
      },
      "outputs": [],
      "source": [
        "#inspecting neutrally classified sentiments\n",
        "data[data['sentiment_category']=='neutral']['content'].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d02480cf",
      "metadata": {
        "id": "d02480cf"
      },
      "source": [
        "## Named Entity Recognition (NER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "681632cc",
      "metadata": {
        "id": "681632cc"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "#nlp = en_core_web_sm.load()\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "nlp.max_length = 1700000\n",
        "#get the pipeline component\n",
        "ner=nlp.get_pipe(\"ner\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4acab636",
      "metadata": {
        "id": "4acab636",
        "outputId": "f0233d55-ca45-4a60-d716-4fe9fd912f0f"
      },
      "outputs": [],
      "source": [
        "panda['Processed_Tweets'].iloc[1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f82f09c",
      "metadata": {
        "id": "6f82f09c"
      },
      "outputs": [],
      "source": [
        "#sample tag text\n",
        "txt=panda['Processed_Tweets'].iloc[1000]\n",
        "doc=nlp(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ee9122",
      "metadata": {
        "id": "d5ee9122",
        "outputId": "ac26a433-4e1e-4f2b-961a-622c6764ad99"
      },
      "outputs": [],
      "source": [
        "def spacy_large_ner(document):\n",
        "    \n",
        "    return {(ent.text.strip(), ent.label_) for ent in nlp(document).ents}\n",
        "spacy_large_ner(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26ba1c4e",
      "metadata": {
        "id": "26ba1c4e",
        "outputId": "f09947a1-a1fa-4f05-e0ac-843ab8c3eb92"
      },
      "outputs": [],
      "source": [
        "## display result\n",
        "spacy.displacy.render(doc,style='ent')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "238bef9b",
      "metadata": {
        "id": "238bef9b"
      },
      "outputs": [],
      "source": [
        "#named_entity_bar_chart\n",
        "def plot_named_entity_barchart(text):\n",
        "    #nlp = spacy.load(\"en_core_web_sm\")\n",
        "    \n",
        "    def _get_ner(text):\n",
        "        doc=nlp(text)\n",
        "        #return {(ent.text.strip(), ent.label_) for ent in nlp(text).ents}\n",
        "        return [X.label_ for X in doc.ents]\n",
        "    \n",
        "    ent=text.apply(lambda x : _get_ner(x))\n",
        "    ent=[x for sub in ent for x in sub]\n",
        "    counter=Counter(ent)\n",
        "    count=counter.most_common()\n",
        "    \n",
        "    x,y=map(list,zip(*count))\n",
        "    sns.barplot(x=y,y=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72dbc83b",
      "metadata": {
        "id": "72dbc83b",
        "outputId": "4bb7db08-32b7-4a61-96ee-263672e0e40d"
      },
      "outputs": [],
      "source": [
        "plot_named_entity_barchart(data['Processed_Tweets'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8be34bb8",
      "metadata": {
        "id": "8be34bb8"
      },
      "source": [
        "PERSON,GPE and ORG dominate the entity bar chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f0babff",
      "metadata": {
        "id": "6f0babff"
      },
      "outputs": [],
      "source": [
        "def plot_most_common_named_entity_barchart(text, entity=\"\"):\n",
        "    #nlp = spacy.load(\"en_core_web_sm\")\n",
        "    \n",
        "    def _get_ner(text,ent):\n",
        "        doc=nlp(text)\n",
        "        return [X.text for X in doc.ents if X.label_ == ent]\n",
        "\n",
        "    entity_filtered=text.apply(lambda x: _get_ner(x,entity))\n",
        "    entity_filtered=[i for x in entity_filtered for i in x]\n",
        "    \n",
        "    counter=Counter(entity_filtered)\n",
        "    x,y=map(list,zip(*counter.most_common(10)))\n",
        "    sns.barplot(y,x).set_title(entity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8215352",
      "metadata": {
        "id": "c8215352",
        "outputId": "ea7d785d-ccc2-4f4b-9b89-1d781f3fa717"
      },
      "outputs": [],
      "source": [
        "plot_most_common_named_entity_barchart(data['Processed_Tweets'],entity='GPE')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b367cf47",
      "metadata": {
        "id": "b367cf47"
      },
      "outputs": [],
      "source": [
        "# creating tokens that will serve as entities for Spacy\n",
        "tokens = nlp(''.join(str(panda['Processed_Tweets'].tolist())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6753e53",
      "metadata": {
        "id": "a6753e53",
        "outputId": "e63d39a7-9aa7-4cf1-9de7-57934c78db1f"
      },
      "outputs": [],
      "source": [
        "# extracting the entities\n",
        "items = [x.text for x in tokens.ents]\n",
        "Counter(items).most_common(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d696e03",
      "metadata": {
        "id": "9d696e03"
      },
      "outputs": [],
      "source": [
        "#extracting the location (GPE)\n",
        "location_list=[]\n",
        "for ent in tokens.ents:\n",
        "    if ent.label_ == 'GPE':\n",
        "        location_list.append(ent.text)\n",
        "location_counts = Counter(location_list).most_common()\n",
        "df_location = pd.DataFrame(location_counts, columns =['country','count'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0ae77e3",
      "metadata": {
        "id": "b0ae77e3",
        "outputId": "ccfe870c-69e5-46d9-b3ca-43dbfad970e9"
      },
      "outputs": [],
      "source": [
        "df_location.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "576bc3e3",
      "metadata": {
        "id": "576bc3e3"
      },
      "outputs": [],
      "source": [
        "#df_location.plot.barh(x='country', y='count', title=\"NER for different locations\", figsize=(10,8)).invert_yaxis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38cfca68",
      "metadata": {
        "id": "38cfca68"
      },
      "outputs": [],
      "source": [
        "# Extracting longitudes and Latitudes \n",
        "#df_location.to_csv('location.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab4d6708",
      "metadata": {
        "id": "ab4d6708"
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv('location.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd86d6b",
      "metadata": {
        "id": "4bd86d6b",
        "outputId": "41fc1dfa-e07c-4037-8995-671fbedd01b2"
      },
      "outputs": [],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b48a55b",
      "metadata": {
        "id": "9b48a55b"
      },
      "outputs": [],
      "source": [
        "#!pip install geopy\n",
        "#!pip install geopandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea21b83",
      "metadata": {
        "id": "9ea21b83"
      },
      "outputs": [],
      "source": [
        "from geopandas.tools import geocode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec96bcd0",
      "metadata": {
        "id": "ec96bcd0",
        "outputId": "1bedfd4c-3bfa-46b7-e1cb-ce811e04dc50"
      },
      "outputs": [],
      "source": [
        "for index,row in df1.iterrows():\n",
        "    try:\n",
        "        print(row['country'])\n",
        "        information=geocode(row['country'],provider='nominatim',user_agent='xyz',timeout=5)\n",
        "        df1.loc[index,'longitude']=information.geometry.loc[0].x\n",
        "        df1.loc[index,'latitude']=information.geometry.loc[0].y\n",
        "    except TypeError:\n",
        "        print('Coordinates of' +row['country']+'are not available')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d050db6c",
      "metadata": {
        "id": "d050db6c",
        "outputId": "c5381f40-c7e1-41f5-8f41-c60a959bff4f"
      },
      "outputs": [],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb7a8007",
      "metadata": {
        "id": "eb7a8007"
      },
      "outputs": [],
      "source": [
        "#save the df1 to a new csv format\n",
        "df1.to_csv('location_geo.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83d3b7f5",
      "metadata": {
        "id": "83d3b7f5"
      },
      "outputs": [],
      "source": [
        "#df2=pd.read_csv('location_geo.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d418d02a",
      "metadata": {
        "id": "d418d02a"
      },
      "source": [
        "## A world map showing location of fall armyworms from different tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a140eb92",
      "metadata": {
        "id": "a140eb92",
        "outputId": "1ed99468-16fb-4d28-c51f-68dea976873a"
      },
      "outputs": [],
      "source": [
        "\n",
        "from shapely.geometry import Point\n",
        "import geopandas as gpd\n",
        "from geopandas import GeoDataFrame\n",
        "\n",
        "df2 = pd.read_csv(\"location_geo.csv\", delimiter=',', skiprows=0, low_memory=False)\n",
        "\n",
        "geometry = [Point(xy) for xy in zip(df2['longitude'], df2['latitude'])]\n",
        "gdf = GeoDataFrame(df2, geometry=geometry)   \n",
        "\n",
        "#a world map with geopandas\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "gdf.plot(ax=world.plot(figsize=(15, 8)), marker='o', color='red', markersize=15);\n",
        "plt.savefig('fallarmyworm_geomap.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e8cba5f",
      "metadata": {
        "id": "2e8cba5f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
